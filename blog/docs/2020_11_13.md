---
date: 2020/11/13
tags: Python, Generators
category: Iterators
author: Michael Green
location: California, United States
---

# Yielding Results, Yielding Control

![Yielding Control]({{ static_assets }}/images/control.jpg)

Last week on this blog we introduced the concept of the generator, as a means for flexibly hooking into Python's iterator protocol. To recap, generators work by using the `yield` keyword so to lazily return sequential values of a function or method. Results are returned by calling the generator's `__next__()` method.

Before moving on from generators however, I wanted to come back once more to this notion of `yield` for one more post, because there's a subtle aspect to `yield` that is often overlooked in much of the Python learning lexicon. Oftentimes, generators are only discussed in the context of yielding results. There is however a second aspect to generators that's worth discussing, and that's the concept of yielding control. 

## A generator as a context manager

I think a clear way to demonstrate this concept of yielding control is in the context of context managers. In one our first blog posts, we demonstrated how we can create ContextManagers by hooking into the context management protocol of python with the `__enter__()` and `__exit__()` methods.

Now, context managers have a more obvious scope for yielding control - one of their main uses is to automate the setup and teardown of `I/O` resources. When a context manager is used, the `__enter__()` method is executed, and then control is returned to the user within the scope of a `with` statement. Once the user's code within the `with` statement is finished executing, control is returned back to the context manager so it can execute its `__exit__()` strategy.

```python
class ContextManager:
    def __enter__(self):
        print('enter ContextManager')

    def __exit__(self, *args, **kwargs):
        print('exit ContextManager')

with ContextManager(): 
    print('within ContextManager')
```

```
In [1]: %run "d:\programming\sandbox\yielding_results_yielding_control.py"
Out[1]: 
enter ContextManager
within ContextManager
exit ContextManager
```

Here, we can see how the developer has full programmatic control within the scope of the ContextManager. But how does this tie back into generators? Well, consider the execution of the given generator below. Here, we can see that after the generator is initialized, calling its `__next__()` method would print `enter generator` and `yield` both control as well as an implicit `None` value to the call source. A subsequent `__next__()` call would return an implicit `StopIteration` to the call source after printing `exit generator`.

```python
def generator():
    print('enter generator')
    yield
    print('exit generator')
```

This is actually an exact mirror of the context manager protocol. So much so that, with a little extra work, we could wrap this function using a `@ContextManager` and the result is an emulation of the context manager via a generator.

```python
class ContextManager():
    def __init__(self, f):
        self.f = f()

    def __call__(self):
        return self

    def __enter__(self):
        self.f.__next__()

    def __exit__(self, *args, **kwargs):
        try:
            self.f.__next__()
        except StopIteration:
            pass


@ContextManager
def generator():
    print('enter generator')
    yield
    print('exit generator')


with generator():
    print('within generator')
```

```python
In [2]: %run "d:\programming\sandbox\yielding_results_yielding_control.py"
Out[2]: 
enter generator
within generator
exit generator
```

The reason I wanted to go through this little exercise is because I think it demonstrates well this concept of yielding control. In this case, execution control is yielded within the scope of the `with` block. Our `@ContextManager` upon entering via `__enter__()`, executes the generator, printing `enter generator` and returning control once the `yield` is reached. At this point, the generator returns control of execution back up the stack to the code within the `with` block, which prints `within generator`. Once the `with` block is exited, the generator resumes control, printing `exit generator` and returning `StopIteration`, which allows the ContextManager to exit the protocol seamlessly. Using this `@ContextManager` we see how control is passed up and down the stack between the generator and the end user.

## Example: Sequencing API calls

One of my jobs as a core library developer with Crunch.io/YouGov is to develop libraries which allow our front-end UI to communicate with both the Crunch API, and by extension the API of our company partners. Obviously we won't be getting into specifics of this proprietary system, but one of the general aspects of API development is the development of tools which have an inherent order of operation - authentication, resource allocation, API responses - many of these aspects of back-end development require a strict protocol order that needs to be enforced. 

That being said, oftentimes these protocols need to be intertwined with other aspects of our libraries. Consider the following example. Here we have a mocked-out HTTP session response which mimics a series of API calls. The API has a `GET` and `POST` endpoint, where the `POST` returns a data object that is dependent on data which is collected from the `GET` request.

```python
import requests
import json

class MockGet:
    def __init__(self, url, data=None):
        self.url = url
        self.text = data
        self.status_code = 200

class MockPost:
    def __init__(self, url, data):
        self.url = url
        self.status_code = 202
        self.text = json.dumps({data: self.return_resp(data)})

    def return_resp(self, data):
        if data == "this":
            return "that"
        elif data == "fizz":
            return "buzz"
        else:
            return "goobar"

class MockSession:
    def get(self, url, data):
        return MockGet(url, data)

    def post(self, url, data):
        return MockPost(url, data)
    
class HTTPResponse:
    def __init__(self, url):
        self.url = url
        self.session = MockSession()
        self.generator = self.generator()

    def GET(self):
        self.resp = self.session.get(self.url, self.url.split("://")[1])

    def POST(self):
        self.resp = self.session.post(self.url, self.resp.text)
```

The benefit we're deriving from this HTTPResponse object is that it allows us to interact with the progression of these API calls. We can do things like authentication, data conformation, etc. However as formulated, this object API has an inherent order that, if not followed, will throw an error at runtime. 

```python
In [3]:
conn = HTTPResponse("mock://fizz")
conn.GET()
assert conn.resp.url.startswith("mock://")
assert conn.resp.status_code == 200
print(conn.resp.text)
conn.POST()
assert conn.resp.url.startswith("mock://")
assert conn.resp.status_code == 202
print(json.loads(conn.resp.text))

Out[3]:
fizz
{'fizz': 'buzz'}
```

```python
In [4]:
conn = HTTPResponse("mock://fizz")
assert conn.url.startswith("mock://")
conn.POST()

Out[4]:
Traceback (most recent call last):
File "d:\Programming\blog\ablog\.sandbox\yielding_results_yielding_control.py" line 211, in <module>
    conn.POST()
File "d:\Programming\blog\ablog\.sandbox\yielding_results_yielding_control.py", line 199, in POST   
    self.resp = self.session.post(self.url, self.text)
File "d:\Programming\blog\ablog\.sandbox\yielding_results_yielding_control.py", line 207, in text   
    return self.resp.text
AttributeError: 'HTTPResponse' object has no attribute 'resp'
```

We can mitigate this issue without losing the desired control over our response object by wrapping the API functionality within the iterator protocol. To do this, lets create a generator method which, when called, executes a single step in the API progression before yielding control back to the user. Because we're only adding a single generator method to this object, we can also go ahead and wrap that in a `__next__()` method of the `HTTPResponse` for further simplicity.

```python
class HTTPResponse:
    def __init__(self, url):
        self.url = url
        self.session = MockSession()
        self.generator = self.generator()

    def __next__(self):
        self.generator.__next__()

    def _GET(self):
        self.resp = self.session.get(self.url, self.url.split("://")[1])

    def _POST(self):
        self.resp = self.session.post(self.url, self.resp.text)

    def generator(self):
        self._GET()
        yield
        self._POST()
        yield
```

This object formulation allows us as library developers to specify the action sequence of our `HTTPResponse` object without usurping an end-users ability to weave their own code into the sequence. End users now only need to call `next()` instead of calling `GET` and `POST` in specific sequence. The result is a user experience that minimizes error without limiting interoperability.

```python
In [5]:
conn = HTTPResponse("mock://this")
assert conn.url.startswith("mock://")
next(conn)
assert conn.url.startswith("mock://")
assert conn.resp.status_code == 200
print(conn.resp.text)
next(conn)
assert conn.url.startswith("mock://")
assert conn.resp.status_code == 202
print(json.loads(conn.resp.text))

Out[5]:
this
{'this': 'that'}
```

## Summary

Generators are a great tool for Python developers. Not only do they allow us to control the timing of yielding results, but they also more fundamentally allow us to yield control of our code with a higher degree of nuance. This concept of yielding control gives us the opportunity to more precisely establish object paradigms and minimize the potential for errors in execution.
