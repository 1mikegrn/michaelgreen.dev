---
date: 2020/10/23
tags: Python, iterators
category: Iterators
author: Michael Green
location: California, United States
---

# Iterating right along...

![Iterator]({{ static_assets }}/images/iterator.jpg)

Over the last few blog posts we've taken the time to discuss how to create various objects within the scope of the Python data model. To reiterate, the Python data model is a set of hooks which allow developers to construct objects which interact with some of the core functionality of the Python programming language. We've previously looked at how to build `__enter__()` and `__exit__()` strategies for use in context managers.

For today's post, we're going to continue with these variations on a theme and look into building Iterators.

## Iterators and the `for` loop

Python is kind of a quirky language. It has many subtle differences that make it unique in terms of its implementation. One of these quirks that often goes unnoticed is how the `for` loop functions within Python.

If you've ever done any programming in `C` or mostly any other C-style language, you'll recognize that the basic `for` loop is constructed as the following:

```C
int main() {
    for (int i=0; i<10; i++) {
        printf("%d ", i);
    }
} 
```

where in `C`, the `for (...)` syntax describes an initialization statement, a conditional statement, and an updating statement for the scope of the loop as it is executed.

This mental model for the `for` loop here is pretty ubiquitous across many of the popular programming languages. However it is fundamentally incorrect when considering Python's `for` loop protocol. As an example, the Python interpreter has no issue executing the following...

```python
for x in [1, 2, 'this', 'that', 'wait we started with numbers why are we looping over strings now...']:
    print(x)
```
        
...even though we clearly don't have any initialization, conditional, or updating statements in this protocol.

The difference here with the Python approach harks back to a comment we made in the [previous](https://1mikegrn.github.io/blog/posts/2020_10_16) blog post regarding Python objects. In Python, everything is an object. As such, the mental model for these `for` loops mirrors that mentality and is thus more so of the form:

```python
for <each object x> in <a container object>:
    use(<each object x>)
```

Where the `for` loop is iteratively calling each object `x` from a sequence of objects defined in a container which is iterable.

## Custom Iterables

The Python data model provides two hooks which allow us to create custom iterables that hook into this iterator protocol; these hooks are `__iter__()` and `__next__()`. The `__iter__()` method returns the object which is the iterable (in this case, `self`). Iterable objects then contain a `__next__()` method, which the Python interpreter continuously calls as the iteration progresses, until `__next__()` raises a `StopIteration` exception. When this exception is raised, Python exits the iteration. If no `StopIteration` exception is raised, the object will continuously iterate (which can be useful in some contexts, but that'll be for a later post).

```python
class CountByTwos:
    def __init__(self, start, stop):
        self.internal_value = start
        self.stop = stop

    def __iter__(self):
        return self

    def __next__(self):
        snapshot = self.internal_value
        if snapshot >= self.stop:
            raise StopIteration
        self.internal_value += 2
        return snapshot      
```

Consider the object above in the context of this iterator protocol. This `CountByTwos` object sets an internal value to the start value. The `__next__()` method takes a snapshot of this internal value, and raises `StopIteration` if the snapshot is greater than or equal to the stop value. If it isn't, we'll increment the internal value by twos, and finally return the snapshot value.

As we would suspect, Iterating over this `CountByTwos` object results in a sequence of values between `start` and `stop` incremented by twos.

```
In [1]: [x for x in CountByTwos(start=4,stop=24)]
Out[1]: [4, 6, 8, 10, 12, 14, 16, 18, 20, 22]
```

## Example: CSV concatenation

A few days ago I came across a thread on LinkedIn asking if it was possible to use Python so to concatenate a set of CSV files into a single monolithic CSV file. As stated, each file contained a row of headers followed by subsequent columns of data. The overall structure of each file was identical - the data was simply spread out over a set of files and the goal was to agglomerate the data to a single source.

If we think about this problem for a minute, we can see that the scope of the desired protocol fits into this iterator model; we simply need to create the containers necessary for iterating over the desired container objects.

```python
with open(<new_file path>, 'w') as <new_file>:
    for <each file f> in <a file container>:
        for <each row of text> in <each file f>:
            <write row of text to new_file, w/o redundant headers>
```

With this iterator model in mind, we can now go ahead and create the iterators necessary for solving this problem. Now, since the goal of this post is to demonstrate iterators, I'm going to explicitly stick to using the iterator protocol for addressing this problem - the solution to this problem would certainly be simpler if we were to also use generators in our solution (and to be fair, generators *are* iterators), but I want to save generators for a future post. So given that, we'll start by creating the iterator for the inner loop, and work our way outward.

The trick here is going to be creating a file iterator which allows us to skip reading the first line depending on whether or not we want the headers returned. We only want the header from a single file - all other header reads will be redundant. We can do this by initializing the FileIterator with a headers boolean, where if it's false, we'll invoke the `next()` call over the file object so to skip to the second line of the file (which means yes, `open()` acts also as an iterator).

```python
from typing import TextIO

class FileIterator:
    def __init__(self, file: TextIO, header: bool) -> None:
        self.file = file
        if not header:
            next(self.file)

    def __iter__(self):
        return self

    def __next__(self) -> str:
        row = self.file.readline()
        if not row:
            self.file.close()
            raise StopIteration
        return row

    @staticmethod
    def from_filepath(path: str, header: bool) -> object:
        return FileIterator(open(path), header)
```

Another benefit of this implementation is that it's more memory efficient. Instead of reading an entire file into memory before operating on its contents, we're breaking it up into 'chunks' of data that are being operated on sequentially. This is similar to what we saw in a [previous](https://1mikegrn.github.io/blog/posts/2020_10_16/) post where we used `csv.reader` as an iterator so to avoid similar memory issues.

Now that we have an object which can iterate over an individual file, let's turn our focus to creating an object which can iterate over a collection of these FileIterators. Within this FileManager object we'll set a `self.header` value which is initialized as `True` and passed to the `FileIterator` on the `FileManager`'s first pass. but once this occurs, we'll flip it to `False` so that future iterations invoke the `if not header` protocol within the `FileIterator`.

```python
import csv
import glob
import os.path


class FileManager:
    def __init__(self, files: list) -> None:
        self.files = files
        self.header = True
        self.file_count = 0

    def __iter__(self):
        return self

    def __next__(self):
        while self.file_count < len(self.files):
            iterator = FileIterator.from_filepath(
                self.files[self.file_count], self.header
            )
            self.header = False
            self.file_count += 1
            return iterator
        raise StopIteration

    @staticmethod
    def from_directory(file_dir: str, ext: str) -> object:
        return FileManager(
            glob.glob(os.path.join(file_dir, "**"+ext))
        )
```

Now that we have our iterators, executing the overall protocol is as simple as calling the `FileManager` and `FileIterator`'s from within a pair of `for` loops. We can do this within the scope of an `open()` context manager so to write the result of the iterables to the opened file.

```python
with open(r'D:\Programming\ZZ_Sandbox\file_iterator\test.txt', 'w') as f:
    for file in FileManager.from_directory(
        r'D:\Programming\ZZ_Sandbox\file_iterator', '.csv'
    ):
        for row in file:
            f.write(row)
```

## Summary

The iterator protocol provides Python developers with the ability to precisely control objects in sequence. By hooking into this iterator protocol using `__iter__()` and `__next__()`, we can create our own iterables with customized sequences. Here, we showed how to implement these `__iter__()` and `__next__()` methods within our own iterables, so to control how file data was read and written in a memory-efficient manner.
