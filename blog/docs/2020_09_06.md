---
date: 2020/09/06
tags: Python, decorators
category: Decorators
author: Michael Green
location: California, United States
---


# In Python, decorators are where it's @

![Decorators]({{ static_assets }}/images/decorators.jpg)

The title of this post is a bit over hyped, predominately due to the fact that decorators fundamentally don't add any extra functionality to the Python programming language. They do however provide an elegant protocol for a design pattern that occurs very often in Python. In this post, I'll show you what that design pattern is, and how to use decorators for providing an elegant solution to these pattern instances.

## Decorators: simple syntactic sugar

I came across a post here on LinkedIn earlier today, where the author was asking his network if they had any applicable examples of decorator usage that they were willing to share. Commenters responded with examples of app routing in Flask, and more-or-less several variations of the standard answer of 'decorators modify functions.' These are all good and valid points, but what I ultimately want to add to this conversation of decorators is the fundamental design pattern that these objects are meant to address.

Fundamentally, a decorator is simply just syntactic sugar for the expression `x = f(x)`, where x is either a class or a def statement. Decorators don't actually add to Python any new functionality; there's nothing that a decorator provides you which you can't already do in Python without the `@` operator. Rather, decorators provide us with an elegant way of explicitly codifying this `x = f(x)` protocol in a way that is clear, explicit, and controlled.

## Example: Memoization and the fibonacci function

The framework I like to use to demonstrate this is in the context of memoization. Consider a recursive fibonacci function, which calculates the n-th fibonacci term.

```
def fibonacci(n: int) -> int:
    if n == 2 or n==1:
        return 1
    elif n > 2:
        return fibonacci(n-1) + fibonacci(n-2)
```

Nothing crazy. And if this was the problem we wanted to solve, it works fine.

However if you were to stick this function into your Python interpreter you would notice that, as n increases, the execution time of this function gets longer and longer. For my computer it starts getting painful past n=40. Why is this?

```
In [1]: timeit.timeit(
        'fibonacci(40)', 
        setup="from __main__ import fibonacci", 
        number=4
    )
Out[1]: 131.346116
```

Well if we consider this recursive function for some term, say `N=7`, and try to map out how this is being executed, it would look something like the following:

```
fibonacci(7)

fibonacci(6) + fibonacci(5)

fibonacci(4) + fibonacci(5) + fibonacci(4) + fibonacci(3)

fibonacci(3) + fibonacci(2) + fibonacci(4) + fibonacci(3) + fibonacci(3) + fibonacci(2) + fibonacci(2) + fibonacci(1)

fibonacci(2) + fibonacci(1) + fibonacci(2) + fibonacci(3) + fibonacci(2) + fibonacci(2) + fibonacci(1) + fibonacci(2) + fibonacci(1) + fibonacci(2) + fibonacci(2) + fibonacci(1)

fibonacci(2) + fibonacci(1) + fibonacci(2) + fibonacci(2) + fibonacci(1) + fibonacci(2) + fibonacci(2) + fibonacci(1) + fibonacci(2) + fibonacci(1) + fibonacci(2) + fibonacci(2) + fibonacci(1)

1+1+1+1+1+1+1+1+1+1+1+1+1

13
```

We can see that our function is doing a lot of unpacking of smaller fibonacci terms, and because of this, we're doing a lot of repeated work in this computation. Repeatedly calculating the results of these fibonacci sub trees is ultimately what is causing our computer to get bogged down at high values of n.

This is where the concept of memoization comes in. Instead of calculating `fib(4)` twice on line three, it would be better for us if we could calculate this internal recursive state once, cache the result, and on the second instance simply grab the cache instead of completely recalculating the whole `fibonacci(4)` recursive tree.

We could write a little object that handles this caching for us. Lets create a Cache object that takes a function and also has a little cache dictionary where we'll store our results. And every time we call this Cache object, we're going to first check the self.cache to see if we've already computed the result. If we haven't, we'll cache it, and then finally we'll simply return the cache value from our internal cache.

```
class Cache(object):
    def __init__(self, f: 'fibonacci') -> None:
        self.f = f
        self.cache = {}

    def __call__(self, n: int) -> int:
        if n not in self.cache:
            self.cache[n] = self.f(n)
        return self.cache[n]
```

Now given the way we wrote this cache object, when we calculate the n-th fibonacci term, we really don't want to actually call the fibonacci function -- we want to instead call the cache of this fibonacci function. I.E. we can write:

```
if __name__ == __main__:
    fibonacci = Cache(fibonacci)
    fibonacci(250)
```

So that when we execute fibonacci(250), we're actually calling Cache.__call__(250) which has an attribute of Cache.f = fibonacci.

This is the original protocol which we saw that decorators are for. So, instead of writing `fibonacci = Cache(fibonacci)` in our main execution, we can write a decorated fibonacci function in our library code so to codify this design pattern.

```
@Cache
def fibonacci(n: int) -> int:
    if n == 2 or n==1:
        return 1
    elif n > 2:
        return fibonacci(n-1) + fibonacci(n-2)
```

And now that we're caching intermediary values, our execution speed is significantly better.

```
In [2]: timeit.timeit(
            'fibonacci(250)', 
            setup="from __main__ import fibonacci", 
            number=4
        )
Out[2]: 0.00094080
```

To note: this notion of caching is so common in Python that there's actually a core library object which does almost exactly what we've demonstrated herein. Next time you want to employ caching in your code, give functools.lru_cache a try from the functools module. And yes, it's a decorator.

## Summary


Decorators provide Python with an elegant means of addressing this `x=f(x)` design pattern. Leveraging their elegance in your library code provides you with the means to codify this pattern in a way that is clear, explicit, and controlled.

*If you enjoyed this post, be sure to [follow me](https://www.linkedin.com/in/1mikegrn/) on LinkedIn, where I'll be posting more content regularly. You can find previous content at my blog's website, [https://blog.michaelgreen.dev](https://blog.michaelgreen.dev)*